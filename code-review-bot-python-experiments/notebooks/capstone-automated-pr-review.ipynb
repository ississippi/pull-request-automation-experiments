{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0213b7-6987-4be3-bc73-e4c99a64eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma bs4\n",
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e263e579-1d15-4f3e-bc32-ffae39af5655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbbe9081-0217-44a4-af71-221a1c8c34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "852b32a7-a586-467e-90a4-3176c7492ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b81f850e-d72e-4c4e-b0d7-2e7e797b27fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(range(0,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7a827c-ca24-442c-9e0a-f08b38bc0186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version = '7'\n",
      "html_title = \"Guzzle Documentation\"\n",
      "html_short_title = \"Guzzle 7\"\n",
      "\n",
      "exclude_patterns = ['_build']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Snippet\n",
    "# Json snippets\n",
    "#\n",
    "# \"snippets\": [\n",
    "#     \"id\"\n",
    "#     \"snippet\"\n",
    "#     \"language\"\n",
    "#     \"repo_file_name\"\n",
    "# ]\n",
    "import json\n",
    "def get_snippet():\n",
    "    # Open and read the JSON file\n",
    "    with open('..\\\\..\\\\test-data\\\\python-snippets.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    snippet = data[\"snippets\"][0][\"snippet\"]\n",
    "    file.close()\n",
    "    return snippet\n",
    "\n",
    "print(get_snippet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c342855-fd95-4aa0-b26a-081e9c60ef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Please review the following Python function for any issues or improvements.'}, {'role': 'user', 'content': 'version = \\'7\\'\\nhtml_title = \"Guzzle Documentation\"\\nhtml_short_title = \"Guzzle 7\"\\n\\nexclude_patterns = [\\'_build\\']\\n'}]\n"
     ]
    }
   ],
   "source": [
    "snippet = get_snippet()\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Please review the following Python function for any issues or improvements.\"},\n",
    "    {\"role\": \"user\", \"content\": snippet}\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e878d9a-8535-47be-8753-d060db9a07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating responsefrom gpt-4-turbo\n",
    "snippet = get_snippet()\n",
    "openai_response40 = client.chat.completions.create(\n",
    "  model = 'gpt-4-turbo',\n",
    "  messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Please review the following Python function for any issues or improvements.\"},\n",
    "    {\"role\": \"user\", \"content\": snippet}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8290e55-3cb3-43d1-9848-a6af63021eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code snippet you posted contains variable assignments but not a function. These variables seem to be configuration settings, possibly for a documentation setup using a tool like Sphinx (common for Python projects). Here's a brief review and some suggestions related to the code:\n",
      "\n",
      "### Code Review\n",
      "\n",
      "1. **Variable Usage:**\n",
      "   - `version`: Seems to indicate the version of the software or documentation. It’s plain and simply put.\n",
      "   - `html_title`: Defines the title of the HTML documentation.\n",
      "   - `html_short_title`: A shorter title for the HTML documentation, useful for header or footer.\n",
      "   - `exclude_patterns`: List containing directories or patterns to exclude, probably from the documentation build process.\n",
      "\n",
      "2. **Consistency and Clarity:**\n",
      "   - Variable names are clear and consistent with what they seem to control or represent.\n",
      "   - String values are correctly enclosed in quotes.\n",
      "   - The list is properly defined.\n",
      "\n",
      "3. **Global Variables:**\n",
      "   - These variables are defined in the global scope. If these are part of a larger Python script or application, it might be better to encapsulate them within a function or a class to avoid potential conflicts or unintended modifications. \n",
      "\n",
      "### Suggestions for Improvement\n",
      "\n",
      "1. **Encapsulation:**\n",
      "   - If these variables are part of a larger system and multiple functions or modules might use or modify them, consider encapsulating them within a class or a specific configuration management setup:\n",
      "     ```python\n",
      "     class Config:\n",
      "         def __init__(self):\n",
      "             self.version = '7'\n",
      "             self.html_title = \"Guzzle Documentation\"\n",
      "             self.html_short_title = \"Guzzle 7\"\n",
      "             self.exclude_patterns = ['_build']\n",
      "     ```\n",
      "   - This encapsulation can help in managing configurations in a centralized manner, particularly useful in larger projects.\n",
      "\n",
      "2. **Type Hints and Documentation:**\n",
      "   - If you're working in a codebase where clarity and maintainability are crucial, especially with others, consider adding type hints:\n",
      "     ```python\n",
      "     version: str = '7'\n",
      "     html_title: str = \"Guzzle Documentation\"\n",
      "     html_short_title: str = \"Guzzle 7\"\n",
      "     exclude_patterns: List[str] = ['_build']\n",
      "     ```\n",
      "   - Adding docstrings or comments explaining why certain values are chosen can also improve maintainability.\n",
      "\n",
      "3. **Dynamic Configuration:**\n",
      "   - If these settings need to be modified often or vary between environments (development, production), consider loading them from an environment variable or a configuration file. This makes the application more flexible and less prone to require code changes for configuration adjustments.\n",
      "\n",
      "4. **Validation:**\n",
      "   - If these configurations are meant to be altered or inputted via user input or external sources at any point, add validation or error-checking to ensure they meet expected patterns or types. This can prevent bugs and crashes related to incorrect configurations.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The provided script is simple and effectively setting configuration variables for what appears to be a document-building process using Sphinx or a similar tool. If this script is part of a larger or more complex program, applying some of the above improvements could aid in maintainability and flexibility. Without more context on how these variables are used within a larger application, these suggestions aim to generalize good programming practices. If there's a specific function or more context you could provide, I'd be able to give a more tailored review or improvement ideas.\n"
     ]
    }
   ],
   "source": [
    "# Print the response\n",
    "print(openai_response40.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de3a525-f6c8-47d5-ae48-4738fbc28ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====1====\n",
      "version = '7'\n",
      "html_title = \"Guzzle Documentation\"\n",
      "html_short_title = \"Guzzle 7\"\n",
      "\n",
      "exclude_patterns = ['_build']\n",
      "\n",
      "\n",
      "====2====\n",
      "    # Path to a touch icon\n",
      "    # \"touch_icon\": \"\",\n",
      "\n",
      "    # Specify a base_url used to generate sitemap.xml links. If not\n",
      "    # specified, then no sitemap will be built.\n",
      "\n",
      "\n",
      "====3====\n",
      "    \"base_url\": \"http://guzzlephp.org\"\n",
      "\n",
      "    # Allow the \"Table of Contents\" page to be defined separately from \"master_doc\"\n",
      "    # tocpage = Contents\n",
      "\n",
      "\n",
      "\n",
      "====4====\n",
      "from tensorflow.python.estimator.model_fn import EstimatorSpec\n",
      "from tensorflow.python.estimator.run_config import RunConfig\n",
      "from tensorflow.python.framework import constant_op\n",
      "from tensorflow.python.framework import dtypes\n",
      "from tensorflow.python.framework import test_util\n",
      "\n",
      "\n",
      "====5====\n",
      "    self.assertFalse(gfile.Exists('ram://exists/a/c'))\n",
      "    self.assertFalse(gfile.Exists('ram://exists/a/b/k'))\n",
      "\n",
      "  def test_estimator(self):\n",
      "\n",
      "\n",
      "\n",
      "====6====\n",
      "    estimator.train(input_fn=input_fn, steps=10)\n",
      "    estimator.train(input_fn=input_fn, steps=10)\n",
      "    estimator.train(input_fn=input_fn, steps=10)\n",
      "    estimator.train(input_fn=input_fn, steps=10)\n",
      "\n",
      "\n",
      "\n",
      "====7====\n",
      "        x,\n",
      "        src_format=src_format_digits,\n",
      "        dst_format=dest_format_digits,\n",
      "        name=fh.get_string())\n",
      "  except (tf.errors.InvalidArgumentError, ValueError, TypeError):\n",
      "\n",
      "\n",
      "====8====\n",
      "    pass\n",
      "\n",
      "\n",
      "def main():\n",
      "  atheris.Setup(sys.argv, TestOneInput, enable_python_coverage=True)\n",
      "\n",
      "\n",
      "====9====\n",
      "      max_int: Maximum allowed integer.\n",
      "\n",
      "    Returns:\n",
      "      Consumed integer based on input bytes and constraints.\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "====10====\n",
      "    Returns:\n",
      "      Consumed integer or float list based on input bytes and constraints.\n",
      "    \"\"\"\n",
      "    if self.get_bool():\n",
      "      return self.get_int_list(min_length, max_length)\n",
      "\n",
      "\n",
      "====11====\n",
      "import sys\n",
      "import atheris_no_libfuzzer as atheris\n",
      "from python_fuzzing import FuzzingHelper\n",
      "import tensorflow as tf\n",
      "\n",
      "\n",
      "\n",
      "====12====\n",
      "          UnicodeEncodeError, UnicodeDecodeError):\n",
      "    pass\n",
      "\n",
      "\n",
      "def main():\n",
      "\n",
      "\n",
      "====13====\n",
      "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====14====\n",
      "\"\"\"Test for version 1 of the zero_out op.\"\"\"\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "\n",
      "====15====\n",
      "      self.assertAllEqual(result, [5, 0, 0, 0, 0])\n",
      "\n",
      "  @test_util.run_deprecated_v1\n",
      "  def test_namespace_call_op_on_op(self):\n",
      "    with self.cached_session():\n",
      "\n",
      "\n",
      "====16====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\n",
      "\n",
      "\n",
      "====17====\n",
      "      self.assertAllEqual(result, [5, 0, 0, 0, 0])\n",
      "\n",
      "  @test_util.run_deprecated_v1\n",
      "  def test_2d(self):\n",
      "    with self.cached_session():\n",
      "\n",
      "\n",
      "====18====\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import argparse\n",
      "\n",
      "\n",
      "====19====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Tests for data input for speech commands.\"\"\"\n",
      "\n",
      "\n",
      "====20====\n",
      "      wav_data = self.evaluate(wav_encoder)\n",
      "    return wav_data\n",
      "\n",
      "  def _saveTestWavFile(self, filename, wav_data):\n",
      "    with open(filename, \"wb\") as f:\n",
      "\n",
      "\n",
      "====21====\n",
      "      self.assertIn(b\"const unsigned char g_input_data\", content)\n",
      "\n",
      "  @test_util.run_deprecated_v1\n",
      "  def testWavToFeaturesMicro(self):\n",
      "    tmp_dir = self.get_temp_dir()\n",
      "\n",
      "\n",
      "====22====\n",
      "                              testing_percentage)\n",
      "      self.prepare_background_data()\n",
      "    self.prepare_processing_graph(model_settings, summaries_dir)\n",
      "\n",
      "  def maybe_download_and_extract_dataset(self, data_url, dest_directory):\n",
      "\n",
      "\n",
      "====23====\n",
      "\n",
      "  def prepare_data_index(self, silence_percentage, unknown_percentage,\n",
      "                         wanted_words, validation_percentage,\n",
      "                         testing_percentage):\n",
      "    \"\"\"Prepares a list of the samples organized by set and label.\n",
      "\n",
      "\n",
      "====24====\n",
      "      for _ in range(silence_size):\n",
      "        self.data_index[set_index].append({\n",
      "            'label': SILENCE_LABEL,\n",
      "            'file': silence_wav_path\n",
      "        })\n",
      "\n",
      "\n",
      "====25====\n",
      "          self.time_shift_offset_placeholder_: time_shift_offset,\n",
      "      }\n",
      "      # Choose a section of background noise to mix in.\n",
      "      if use_background or sample['label'] == SILENCE_LABEL:\n",
      "        background_index = np.random.randint(len(self.background_data))\n",
      "\n",
      "\n",
      "====26====\n",
      "      else:\n",
      "        input_dict[self.foreground_volume_placeholder_] = 1\n",
      "      # Run the graph to produce the output audio.\n",
      "      summary, data_tensor = sess.run(\n",
      "          [self.merged_summaries_, self.output_], feed_dict=input_dict)\n",
      "\n",
      "\n",
      "====27====\n",
      "  def __init__(self, **entries):\n",
      "    self.__dict__.update(entries)\n",
      "\n",
      "\n",
      "class TrainTest(test.TestCase):\n",
      "\n",
      "\n",
      "====28====\n",
      "  Raises:\n",
      "    Exception: If the preprocessing mode isn't recognized.\n",
      "  \"\"\"\n",
      "\n",
      "  words_list = input_data.prepare_words_list(wanted_words.split(','))\n",
      "\n",
      "\n",
      "====29====\n",
      "      stride=model_settings['window_stride_samples'],\n",
      "      magnitude_squared=True)\n",
      "\n",
      "  if preprocess == 'average':\n",
      "    fingerprint_input = tf.nn.pool(\n",
      "\n",
      "\n",
      "====30====\n",
      "  logits = models.create_model(\n",
      "      reshaped_input, model_settings, model_architecture, is_training=False,\n",
      "      runtime_settings=runtime_settings)\n",
      "\n",
      "  # Create an output to use for inference.\n",
      "\n",
      "\n",
      "====31====\n",
      "\n",
      "The model, labels and .wav file specified in the arguments will be loaded, and\n",
      "then the predictions from running the model against the audio data will be\n",
      "printed to the console. This is a useful script for sanity checking trained\n",
      "models, and as an example of how to use an audio model from Python.\n",
      "\n",
      "\n",
      "====32====\n",
      "\n",
      "Here's an example of generating a test file:\n",
      "\n",
      "bazel run tensorflow/examples/speech_commands:generate_streaming_test_wav -- \\\n",
      "--data_dir=/tmp/my_wavs --background_dir=/tmp/my_backgrounds \\\n",
      "\n",
      "\n",
      "====33====\n",
      "\n",
      "  output_audio_sample_count = FLAGS.sample_rate * FLAGS.test_duration_seconds\n",
      "  output_audio = np.zeros((output_audio_sample_count,), dtype=np.float32)\n",
      "\n",
      "  # Set up background audio.\n",
      "\n",
      "\n",
      "====34====\n",
      "      How loud the background noise should be, between 0 and 1.\n",
      "      \"\"\")\n",
      "  parser.add_argument(\n",
      "      '--background_frequency',\n",
      "      type=float,\n",
      "\n",
      "\n",
      "====35====\n",
      "      default='/tmp/speech_commands_train/streaming_test_labels.txt',\n",
      "      help='File to save the generated test labels to.')\n",
      "  parser.add_argument(\n",
      "      '--test_duration_seconds',\n",
      "      type=int,\n",
      "\n",
      "\n",
      "====36====\n",
      "\n",
      "  @property\n",
      "  def founded_command(self):\n",
      "    return self._founded_command\n",
      "\n",
      "\n",
      "\n",
      "====37====\n",
      "    _suppression_ms: Milliseconds every two reliable founded commands should\n",
      "      apart.\n",
      "    _minimum_count: An integer count indicating the minimum results the average\n",
      "      window should cover.\n",
      "    _previous_results: A deque to store previous results.\n",
      "\n",
      "\n",
      "====38====\n",
      "    window_stride_ms: How far to move in time between spectrogram timeslices.\n",
      "    feature_bin_count: How many bins to use for the feature fingerprint.\n",
      "    quantize: Whether to train the model for eight-bit deployment.\n",
      "    preprocess: Spectrogram processing mode; \"mfcc\", \"average\" or \"micro\".\n",
      "    input_wav: Path to the audio WAV file to read.\n",
      "\n",
      "\n",
      "====39====\n",
      "        if quantized_value < 0:\n",
      "          quantized_value = 0\n",
      "        if quantized_value > 255:\n",
      "          quantized_value = 255\n",
      "        if i == 0:\n",
      "\n",
      "\n",
      "====40====\n",
      "          wanted_words='a,b,c,d',\n",
      "          sample_rate=16000,\n",
      "          clip_duration_ms=1000.0,\n",
      "          clip_stride_ms=30.0,\n",
      "          window_size_ms=30.0,\n",
      "\n",
      "\n",
      "====41====\n",
      "      labels=label_list,\n",
      "      average_window_duration_ms=FLAGS.average_window_duration_ms,\n",
      "      detection_threshold=FLAGS.detection_threshold,\n",
      "      suppression_ms=FLAGS.suppression_ms,\n",
      "      minimum_count=4)\n",
      "\n",
      "\n",
      "====42====\n",
      "        outputs = sess.run(\n",
      "            output_softmax_tensor,\n",
      "            feed_dict={\n",
      "                data_tensor:\n",
      "                    numpy.expand_dims(data[input_start:input_end], axis=-1),\n",
      "\n",
      "\n",
      "====43====\n",
      "            except ValueError as e:\n",
      "              tf.compat.v1.logging.error(\n",
      "                  'Statistics delta computing failed: {}'.format(e))\n",
      "            else:\n",
      "              tf.compat.v1.logging.info('{}ms {}:{}{}'.format(\n",
      "\n",
      "\n",
      "====44====\n",
      "      shape=[first_fc_output_channels])\n",
      "  first_fc = tf.matmul(flattened_first_conv, first_fc_weights) + first_fc_bias\n",
      "  if is_training:\n",
      "    second_fc_input = tf.nn.dropout(first_fc, rate=dropout_rate)\n",
      "  else:\n",
      "\n",
      "\n",
      "====45====\n",
      "  # weights_time: [num_filters, input_time_size, 1]\n",
      "  # outputs: [num_filters, batch, 1]\n",
      "  weights_time = tf.expand_dims(weights_time, 2)\n",
      "  outputs = tf.matmul(activations_time, weights_time)\n",
      "  # Split num_units and rank into separate dimensions (the remaining\n",
      "\n",
      "\n",
      "====46====\n",
      "  bias = tf.compat.v1.get_variable(name='bias',\n",
      "                                   initializer=tf.compat.v1.zeros_initializer,\n",
      "                                   shape=[num_units])\n",
      "  first_bias = tf.nn.bias_add(units_output, bias)\n",
      "\n",
      "\n",
      "\n",
      "====47====\n",
      "  # Relu.\n",
      "  first_relu = tf.nn.relu(first_bias)\n",
      "\n",
      "  if is_training:\n",
      "    first_dropout = tf.nn.dropout(first_relu, rate=dropout_rate)\n",
      "\n",
      "\n",
      "====48====\n",
      "  placeholder.\n",
      "\n",
      "  Args:\n",
      "    fingerprint_input: TensorFlow node that will output audio feature vectors.\n",
      "    model_settings: Dictionary of information about the model.\n",
      "\n",
      "\n",
      "====49====\n",
      "  def _saveWavFolders(self, root_dir, labels, how_many):\n",
      "    wav_data = self._getWavData()\n",
      "    for label in labels:\n",
      "      dir_name = os.path.join(root_dir, label)\n",
      "      os.mkdir(dir_name)\n",
      "\n",
      "\n",
      "====50====\n",
      "\n",
      "  def testWhichSet(self):\n",
      "    self.assertEqual(\n",
      "        input_data.which_set(\"foo.wav\", 10, 10),\n",
      "        input_data.which_set(\"foo.wav\", 10, 10))\n",
      "\n",
      "\n",
      "====51====\n",
      "  def testPrepareDataIndex(self):\n",
      "    tmp_dir = self.get_temp_dir()\n",
      "    self._saveWavFolders(tmp_dir, [\"a\", \"b\", \"c\"], 100)\n",
      "    audio_processor = input_data.AudioProcessor(\"\", tmp_dir, 10, 10,\n",
      "                                                [\"a\", \"b\"], 10, 10,\n",
      "\n",
      "\n",
      "====52====\n",
      "bazel run tensorflow/examples/speech_commands:train\n",
      "\n",
      "This will write out checkpoints to /tmp/speech_commands_train/, and will\n",
      "download over 1GB of open source training data, so you'll need enough free space\n",
      "and a good internet connection. The default data is a collection of thousands of\n",
      "\n",
      "\n",
      "====53====\n",
      "organized by label. For example, here's a possible file structure:\n",
      "\n",
      "my_wavs >\n",
      "  up >\n",
      "    audio_0.wav\n",
      "\n",
      "\n",
      "====54====\n",
      "  # training data of your own, use `--data_url= ` on the command line to avoid\n",
      "  # downloading.\n",
      "  model_settings = models.prepare_model_settings(\n",
      "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
      "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
      "\n",
      "\n",
      "====55====\n",
      "  # Define loss and optimizer\n",
      "  ground_truth_input = tf.compat.v1.placeholder(\n",
      "      tf.int64, [None], name='groundtruth_input')\n",
      "\n",
      "  # Optionally we can add runtime checks to spot when NaNs or other symptoms of\n",
      "\n",
      "\n",
      "====56====\n",
      "\n",
      "  tf.compat.v1.logging.info('Training from step: %d ', start_step)\n",
      "\n",
      "  # Save graph.pbtxt.\n",
      "  tf.io.write_graph(sess.graph_def, FLAGS.train_dir,\n",
      "\n",
      "\n",
      "====57====\n",
      "      if training_step <= training_steps_sum:\n",
      "        learning_rate_value = learning_rates_list[i]\n",
      "        break\n",
      "    # Pull the audio samples we'll use for training.\n",
      "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
      "\n",
      "\n",
      "====58====\n",
      "      type=str,\n",
      "      default='/tmp/speech_dataset/',\n",
      "      help=\"\"\"\\\n",
      "      Where to download the speech training data to.\n",
      "      \"\"\")\n",
      "\n",
      "\n",
      "====59====\n",
      "  parser.add_argument(\n",
      "      '--window_stride_ms',\n",
      "      type=float,\n",
      "      default=10.0,\n",
      "      help='How far to move in time between spectrogram timeslices.',\n",
      "\n",
      "\n",
      "====60====\n",
      "      help='How many bins to use for the MFCC fingerprint',\n",
      "  )\n",
      "  parser.add_argument(\n",
      "      '--how_many_training_steps',\n",
      "      type=str,\n",
      "\n",
      "\n",
      "====61====\n",
      "\n",
      "  tf_module = module_ctor()\n",
      "  options = save_options.SaveOptions(save_debug_info=True)\n",
      "  saved_model.save(tf_module, export_path, options=options)\n",
      "\n",
      "\n",
      "\n",
      "====62====\n",
      "        (3, FindSchema(\"schema_v3.fbs\"), False, None)  # Non-callable by design.\n",
      "    ]\n",
      "    # Ensure schemas are sorted, and extract latest version and upgrade\n",
      "    # dispatch function table.\n",
      "    self._schemas.sort()\n",
      "\n",
      "\n",
      "====63====\n",
      "    self._new_version, self._new_schema = self._schemas[-1][:2]\n",
      "    self._upgrade_dispatch = {\n",
      "        version: dispatch\n",
      "        for version, unused1, unused2, dispatch in self._schemas}\n",
      "\n",
      "\n",
      "\n",
      "====64====\n",
      "        json_file = input_file\n",
      "      else:\n",
      "        raise ValueError(\"Invalid extension on input file %r\" % input_file)\n",
      "      return json.load(open(json_file))\n",
      "\n",
      "\n",
      "\n",
      "====65====\n",
      "      elif extension in [\".tflite\", \".bin\"]:\n",
      "        input_json = os.path.join(tempdir, \"temp.json\")\n",
      "        with open(input_json, \"w\") as fp:\n",
      "          json.dump(data, fp, sort_keys=True, indent=2)\n",
      "        returncode = subprocess.call([\n",
      "\n",
      "\n",
      "====66====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Testing for updating TensorFlow lite schema.\"\"\"\n",
      "\n",
      "\n",
      "====67====\n",
      "        {\n",
      "            \"builtin_code\": \"DEPTHWISE_CONV_2D\"\n",
      "        },\n",
      "        {\n",
      "            \"builtin_code\": \"AVERAGE_POOL_2D\"\n",
      "\n",
      "\n",
      "====68====\n",
      "            },\n",
      "            {\n",
      "                \"builtin_options_type\": \"Conv2DOptions\"\n",
      "            },\n",
      "            {\n",
      "\n",
      "\n",
      "====69====\n",
      "    if floating_model:\n",
      "      print('{:08.6f}: {}'.format(float(results[i]), labels[i]))\n",
      "    else:\n",
      "      print('{:08.6f}: {}'.format(float(results[i] / 255.0), labels[i]))\n",
      "\n",
      "\n",
      "\n",
      "====70====\n",
      "  options.no_tests_limit = FLAGS.no_tests_limit\n",
      "  options.no_conversion_report = FLAGS.no_conversion_report\n",
      "  options.mlir_quantizer = FLAGS.mlir_quantizer\n",
      "\n",
      "  if FLAGS.test_sets:\n",
      "\n",
      "\n",
      "====71====\n",
      "import traceback\n",
      "import zipfile\n",
      "\n",
      "import numpy as np\n",
      "from six import StringIO\n",
      "\n",
      "\n",
      "====72====\n",
      "  if dtype in (tf.float32, tf.float16, tf.float64):\n",
      "    value = (max_value - min_value) * np.random.random() + min_value\n",
      "  elif dtype in (tf.int32, tf.uint8, tf.int64, tf.int16):\n",
      "    value = np.random.randint(min_value, max_value + 1)\n",
      "  elif dtype == tf.bool:\n",
      "\n",
      "\n",
      "====73====\n",
      "  fp.write(\"test_cases,%d\\n\" % len(examples))\n",
      "  for example in examples:\n",
      "    fp.write(\"inputs,%d\\n\" % len(example[\"inputs\"]))\n",
      "    for i in example[\"inputs\"]:\n",
      "      write_tensor(fp, i)\n",
      "\n",
      "\n",
      "====74====\n",
      "    extra_toco_options.inference_input_type = tf.uint8\n",
      "    extra_toco_options.inference_output_type = tf.uint8\n",
      "    # Only count parameters when fully_quantize is True.\n",
      "    parameter_count = 0\n",
      "    for parameters in test_parameters:\n",
      "\n",
      "\n",
      "====75====\n",
      "            input_tensors,\n",
      "            output_tensors,\n",
      "            extra_toco_options=extra_toco_options,\n",
      "            test_params=param_dict_real)\n",
      "        report[\"converter\"] = (\n",
      "\n",
      "\n",
      "====76====\n",
      "          zipinfo = zipfile.ZipInfo(zip_path_label + \"_tests.txt\")\n",
      "          archive.writestr(zipinfo, example_fp2.getvalue(),\n",
      "                           zipfile.ZIP_DEFLATED)\n",
      "\n",
      "          zip_manifest_label = zip_path_label + \" \" + label\n",
      "\n",
      "\n",
      "====77====\n",
      "        ignore_error = False\n",
      "        if not options.known_bugs_are_errors:\n",
      "          for pattern, bug_number in options.known_bugs.items():\n",
      "            if re.search(pattern, label):\n",
      "              print(\"Ignored converter error due to bug %s\" % bug_number)\n",
      "\n",
      "\n",
      "====78====\n",
      "                      escape_and_normalize(x[1][\"converter_log\"])\n",
      "                     ] for x in reports])\n",
      "  fp.write(logs)\n",
      "  fp.write(\";</script>\\n\")\n",
      "\n",
      "\n",
      "\n",
      "====79====\n",
      "      },\n",
      "  ]\n",
      "\n",
      "  def build_graph(parameters):\n",
      "    \"\"\"Build the gather op testing graph.\"\"\"\n",
      "\n",
      "\n",
      "====80====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for lstm.\"\"\"\n",
      "\n",
      "\n",
      "====81====\n",
      "@register_make_test_function()\n",
      "def make_matrix_diag_tests(options):\n",
      "  \"\"\"Make a set of tests for tf.linalg.diag op.\"\"\"\n",
      "\n",
      "  test_parameters = [\n",
      "\n",
      "\n",
      "====82====\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "\n",
      "\n",
      "====83====\n",
      "  test_parameters = [\n",
      "      # Avoid creating all combinations to keep the test size small.\n",
      "      {\n",
      "          \"dtype\": [tf.float32],\n",
      "          \"base_shape\": [[3, 4, 3], [3, 4], [5]],\n",
      "\n",
      "\n",
      "====84====\n",
      "@register_make_test_function()\n",
      "def make_reverse_sequence_tests(options):\n",
      "  \"\"\"Make a set of tests to do reverse_sequence.\"\"\"\n",
      "\n",
      "  test_parameters = [{\n",
      "\n",
      "\n",
      "====85====\n",
      "  }, {\n",
      "      \"input_dtype\": [tf.float32],\n",
      "      \"input_shape\": [[2, 4, 5, 5, 6]],\n",
      "      \"seq_lengths\": [[2, 1]],\n",
      "      \"seq_axis\": [2],\n",
      "\n",
      "\n",
      "====86====\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====87====\n",
      "      \"input_dtype\": [tf.float32, tf.int32],\n",
      "      \"input_shape\": [[], [0], [1, 1, 1, 3], [2, 3, 4, 5], [5, 5], [10]],\n",
      "  }]\n",
      "\n",
      "  def build_graph(parameters):\n",
      "\n",
      "\n",
      "====88====\n",
      "        shape=parameters[\"input_shape\"])\n",
      "    if parameters[\"constant_indices\"]:\n",
      "      begin = parameters[\"begin\"]\n",
      "      end = parameters[\"end\"]\n",
      "      strides = parameters[\"strides\"]\n",
      "\n",
      "\n",
      "====89====\n",
      "          \"begin_mask\": [None, 1, 2],\n",
      "          \"end_mask\": [None, 1, 2],\n",
      "          \"shrink_axis_mask\": [None, 1, 2, 3, -1],\n",
      "          \"constant_indices\": [False, True],\n",
      "          \"fully_quantize\": [False],\n",
      "\n",
      "\n",
      "====90====\n",
      "  if options.use_experimental_converter:\n",
      "    test_parameters = test_parameters + [\n",
      "        # Begin equal to input dim.\n",
      "        {\n",
      "            \"dtype\": [tf.float32],\n",
      "\n",
      "\n",
      "====91====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====92====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for floor.\"\"\"\n",
      "\n",
      "\n",
      "====93====\n",
      "\n",
      "  def build_graph(parameters):\n",
      "    \"\"\"Build the global batch norm testing graph.\"\"\"\n",
      "    input_shape = parameters[\"input_shape\"]\n",
      "    scale_shape = input_shape[3]\n",
      "\n",
      "\n",
      "====94====\n",
      "    out = tf.add(input_tensor, x_norm)\n",
      "    return [input_tensor], [out]\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "    input_value = create_tensor_data(parameters[\"dtype\"],\n",
      "\n",
      "\n",
      "====95====\n",
      "    return all_tensors, [out]\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "    all_values = []\n",
      "    for n in range(0, parameters[\"num_tensors\"]):\n",
      "\n",
      "\n",
      "====96====\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "\n",
      "\n",
      "====97====\n",
      "@register_make_test_function()\n",
      "def make_hardswish_tests(options):\n",
      "  \"\"\"Make a set of tests to do hardswish.\"\"\"\n",
      "\n",
      "  # Chose a set of parameters\n",
      "\n",
      "\n",
      "====98====\n",
      "          \"paddings\": [[[0, 1], [2, 3]]],\n",
      "          \"constant_paddings\": [True, False],\n",
      "          \"constant_values\": [0, 2],\n",
      "      },\n",
      "      # 1D:\n",
      "\n",
      "\n",
      "====99====\n",
      "\n",
      "    # Chose a set of parameters\n",
      "    test_parameters = [\n",
      "        {\n",
      "            \"ksize\": [[2, 1, 1, 2], [1, 1, 1, 1], [1, 1, 2, 1], [1, 10, 11, 1]],\n",
      "\n",
      "\n",
      "====100====\n",
      "        shape=parameters[\"input_shape_pair\"][1])\n",
      "    out = tf.less_equal(input_value1, input_value2)\n",
      "    return [input_value1, input_value2], [out]\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "\n",
      "\n",
      "====101====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for zeros_like.\"\"\"\n",
      "\n",
      "\n",
      "====102====\n",
      "    # the resulting tflite graph retains the zeros_like as a Fill op, which\n",
      "    # is unsupported by TFLite, even as a custom op.\n",
      "    out = tf.maximum(zeros, input_tensor)\n",
      "    return [input_tensor], [out]\n",
      "\n",
      "\n",
      "\n",
      "====103====\n",
      "      input_value = create_scalar_data(parameters[\"value_dtype\"])\n",
      "    else:\n",
      "      input_value = create_tensor_data(parameters[\"value_dtype\"],\n",
      "                                       [parameters[\"value_count\"]])\n",
      "    return [input_value], sess.run(\n",
      "\n",
      "\n",
      "====104====\n",
      "          min_value=-1,\n",
      "          max_value=1)\n",
      "    else:\n",
      "      input1 = create_tensor_data(parameters[\"dtype\"],\n",
      "                                  parameters[\"input_shape_1\"])\n",
      "\n",
      "\n",
      "====105====\n",
      "            inputs[1]: input2\n",
      "        })\n",
      "\n",
      "  make_zip_of_tests(\n",
      "      options,\n",
      "\n",
      "\n",
      "====106====\n",
      "      test_parameters,\n",
      "      build_graph,\n",
      "      build_inputs,\n",
      "      expected_tf_failures=expected_tf_failures)\n",
      "\n",
      "\n",
      "\n",
      "====107====\n",
      "  make_binary_op_tests(options, tf.math.floormod)\n",
      "\n",
      "\n",
      "@register_make_test_function()\n",
      "def make_squared_difference_tests(options):\n",
      "\n",
      "\n",
      "====108====\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "====109====\n",
      "      {\n",
      "          \"dtype\": [tf.float32],\n",
      "          \"input_shape\": [[2, 3, 7, 3]],\n",
      "          \"block_shape\": [[1, 3], [2, 2]],\n",
      "          \"paddings\": [[[0, 0], [2, 0]], [[1, 0], [1, 0]]],\n",
      "\n",
      "\n",
      "====110====\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "====111====\n",
      "      },\n",
      "      {\n",
      "          \"input_shape\": [[3]],\n",
      "          \"padding_matrix\": [[[0, 2]]],\n",
      "          \"mode\": [\"SYMMETRIC\"],\n",
      "\n",
      "\n",
      "====112====\n",
      "    return [indices, updates, shape], [out]\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "    indices = np.array(parameters[\"indices_value\"])\n",
      "    updates = create_tensor_data(parameters[\"updates_dtype\"],\n",
      "\n",
      "\n",
      "====113====\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "====114====\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "\n",
      "\n",
      "====115====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====116====\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "\n",
      "\n",
      "====117====\n",
      "          \"has_bias\": [False],\n",
      "          \"strides\": [[1, 1, 1, 1], [1, 3, 3, 1]],\n",
      "          \"padding\": [\"SAME\", \"VALID\"],\n",
      "          \"data_format\": [\"NHWC\"],\n",
      "          \"channel_multiplier\": [1, 2],\n",
      "\n",
      "\n",
      "====118====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====119====\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "\n",
      "\n",
      "====120====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for exp.\"\"\"\n",
      "\n",
      "\n",
      "====121====\n",
      "    # Add the 2 results up.\n",
      "    out = result1 + result2\n",
      "    return input_tensors, [out]\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "\n",
      "\n",
      "====122====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====123====\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import tensorflow.compat.v1 as tf\n",
      "\n",
      "\n",
      "====124====\n",
      "  test_parameters = [{\n",
      "      \"dims_dtype\": [tf.int32, tf.int64],\n",
      "      \"dims_shape\": [[], [1], [3], [3, 3]],\n",
      "      \"value_dtype\": [tf.int32, tf.int64, tf.float32, tf.bool, tf.string],\n",
      "  }]\n",
      "\n",
      "\n",
      "====125====\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====126====\n",
      "      unread_input = tf.compat.v1.placeholder(\n",
      "          dtype=parameters[\"dtype\"],\n",
      "          name=\"unread_input\",\n",
      "          shape=parameters[\"input_shape\"])\n",
      "      inputs.append(unread_input)\n",
      "\n",
      "\n",
      "====127====\n",
      "      \"input_dtype\": [tf.float32],\n",
      "      \"input_shape\": [[], [1], [1, 2], [5, 6, 7, 8], [3, 4, 5, 6]],\n",
      "  }]\n",
      "\n",
      "  def build_graph(parameters):\n",
      "\n",
      "\n",
      "====128====\n",
      "\n",
      "def make_conv_activation_tests(activation_op):\n",
      "  \"\"\"Make a set of tests to do convolution with activation.\"\"\"\n",
      "\n",
      "  def f(options):\n",
      "\n",
      "\n",
      "====129====\n",
      "    \"\"\"Actual function that generates examples.\"\"\"\n",
      "    test_parameters = [\n",
      "        {\n",
      "            \"input_shape\": [[1, 3, 4, 3], [4, 6, 6, 1]],\n",
      "            \"filter_shape\": [[1, 1], [2, 3], [3, 3]],\n",
      "\n",
      "\n",
      "====130====\n",
      "      # Get filter input either as a placeholder or constants. Also get a list\n",
      "      # of the input tensors that are represented as placeholders.\n",
      "      if parameters[\"constant_filter\"]:\n",
      "        filter_input = create_tensor_data(\n",
      "            np.float32, filter_shape, min_value=-10, max_value=10)\n",
      "\n",
      "\n",
      "====131====\n",
      "      values = [\n",
      "          create_tensor_data(\n",
      "              np.float32, input_shape, min_value=-1, max_value=1)\n",
      "      ]\n",
      "      if not parameters[\"constant_filter\"]:\n",
      "\n",
      "\n",
      "====132====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====133====\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====134====\n",
      "      \"align_corners\": [True, False],\n",
      "      \"half_pixel_centers\": [False],\n",
      "      \"fully_quantize\": [True]\n",
      "  }, {\n",
      "      \"dtype\": [tf.float32],\n",
      "\n",
      "\n",
      "====135====\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====136====\n",
      "      },\n",
      "      {\n",
      "          \"params_dtype\": [tf.float32, tf.int32, tf.int64, tf.string],\n",
      "          \"params_shape\": [[5, 5]],\n",
      "          \"indices_dtype\": [tf.int32, tf.int64],\n",
      "\n",
      "\n",
      "====137====\n",
      "          \"indices_shape\": [[2, 1], [2, 2]],\n",
      "      },\n",
      "      {\n",
      "          \"params_dtype\": [tf.float32, tf.int32, tf.int64, tf.string],\n",
      "          \"params_shape\": [[5, 5, 10]],\n",
      "\n",
      "\n",
      "====138====\n",
      "# TODO(chaomei): refactor the test to cover more cases, like negative stride,\n",
      "# negative array index etc.\n",
      "@register_make_test_function()\n",
      "def make_resolve_constant_strided_slice_tests(options):\n",
      "  \"\"\"Make a set of tests to show strided_slice yields incorrect results.\"\"\"\n",
      "\n",
      "\n",
      "====139====\n",
      "    del parameters\n",
      "    input_values = np.zeros([4, 2], dtype=np.float32)\n",
      "    return [input_values], sess.run(\n",
      "        outputs, feed_dict={inputs[0]: input_values})\n",
      "\n",
      "\n",
      "\n",
      "====140====\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "====141====\n",
      "      \"dtype\": [tf.int32, tf.float32, tf.int64],\n",
      "      \"input_shape\": [[1, 2, 1, 3, 1, 4, 1, 1]],\n",
      "      \"axis\": [\n",
      "          None, [], [0, 2], [4, 7], [-1, 0, 2, 0, 7, -6], [1], [2, 3, 2],\n",
      "          [-1, -2, -4, -6, -8], [0, 2, 4, 6, 7], [7, 6, 4, 2, 0], [6, 6],\n",
      "\n",
      "\n",
      "====142====\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "====143====\n",
      "      \"quant_16x8\": [False]\n",
      "  }, {\n",
      "      \"shape1\": [[40, 37]],\n",
      "      \"shape2\": [[37, 40]],\n",
      "      \"transpose_a\": [False],\n",
      "\n",
      "\n",
      "====144====\n",
      "      # 1-D case\n",
      "      {\n",
      "          \"dtype\": [tf.float32],\n",
      "          \"shape\": [[44]],\n",
      "          \"spec\": [[slice(3, 7, 2)], [tf.newaxis, slice(None)]],\n",
      "\n",
      "\n",
      "====145====\n",
      "        name=\"input1\",\n",
      "        shape=parameters[\"input_shape_pair\"][0])\n",
      "    input_value2 = tf.compat.v1.placeholder(\n",
      "        dtype=parameters[\"input_dtype\"],\n",
      "        name=\"input2\",\n",
      "\n",
      "\n",
      "====146====\n",
      "      axis -= 1\n",
      "    return axis\n",
      "\n",
      "  def build_graph(parameters):\n",
      "    input_tensor = tf.compat.v1.placeholder(\n",
      "\n",
      "\n",
      "====147====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====148====\n",
      "        dtype=parameters[\"indices_type\"],\n",
      "        name=\"indices\",\n",
      "        shape=parameters[\"indices_shape\"])\n",
      "    depth = tf.compat.v1.placeholder(dtype=tf.int32, name=\"depth\", shape=())\n",
      "\n",
      "\n",
      "\n",
      "====149====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====150====\n",
      "\n",
      "@register_make_test_function()\n",
      "def make_tanh_tests(options):\n",
      "  \"\"\"Make a set of tests to do tanh.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "====151====\n",
      "      {\n",
      "          \"input_dtype\": [tf.float32, tf.int32],\n",
      "          \"input_shape_set\": [([1, 2, 3, 4], [1, 2, 3, 4]),],\n",
      "          \"use_where_v2\": [False, True],\n",
      "          \"fully_quantize\": [False],\n",
      "\n",
      "\n",
      "====152====\n",
      "            \"input_dtype\": [tf.float32],\n",
      "            \"input_shape_set\": [([8, 7, 6, 5, 4, 3, 2, 1], [4, 3, 2, 1]),],\n",
      "            \"use_where_v2\": [True],\n",
      "            \"fully_quantize\": [True],\n",
      "        },\n",
      "\n",
      "\n",
      "====153====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for identity.\"\"\"\n",
      "\n",
      "\n",
      "====154====\n",
      "      \"input_shape\": [[3, 4, 5, 7], [4, 105], [21, 5, 2, 2], [420]],\n",
      "      \"output_shape\": [[15, 28], [420], [1, -1, 5, 7], [-1]],\n",
      "      \"constant_shape\": [True],\n",
      "      \"fully_quantize\": [True],\n",
      "  }]\n",
      "\n",
      "\n",
      "====155====\n",
      "      output_shape = tf.compat.v1.placeholder(\n",
      "          dtype=tf.int32, name=\"output_shape\", shape=shape_tensor_shape)\n",
      "      input_tensors = [input_tensor, output_shape]\n",
      "    out = tf.reshape(input_tensor, shape=output_shape)\n",
      "    return input_tensors, [out]\n",
      "\n",
      "\n",
      "====156====\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "    \"\"\"Build inputs for slice test.\"\"\"\n",
      "    input_values = create_tensor_data(\n",
      "        parameters[\"dtype\"],\n",
      "\n",
      "\n",
      "====157====\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====158====\n",
      "@register_make_test_function()\n",
      "def make_unpack_tests(options):\n",
      "  \"\"\"Make a set of tests to do unpack.\"\"\"\n",
      "\n",
      "  test_parameters = [{\n",
      "\n",
      "\n",
      "====159====\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_scalar_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "\n",
      "====160====\n",
      "        is_training=parameters[\"is_training\"])\n",
      "\n",
      "    input_tensor = tf.compat.v1.placeholder(\n",
      "        dtype=parameters[\"dtype\"],\n",
      "        name=\"input\",\n",
      "\n",
      "\n",
      "====161====\n",
      "\n",
      "  def build_inputs(parameters, sess, inputs, outputs):\n",
      "    input_values = []\n",
      "    if not parameters[\"constant_params\"]:\n",
      "      params = create_tensor_data(parameters[\"params_dtype\"],\n",
      "\n",
      "\n",
      "====162====\n",
      "          \"channel_multiplier\": [2],\n",
      "          \"rate\": [[2, 2]],  #  Only [1, 1] is supported\n",
      "          \"padding\": [\"SAME\"],\n",
      "          \"data_format\": [\"NHWC\"],\n",
      "          \"constant_filter\": [True, False],\n",
      "\n",
      "\n",
      "====163====\n",
      "          \"constant_filter\": [True],\n",
      "          \"fully_quantize\": [True],\n",
      "          \"quant_16x8\": [True]\n",
      "      },\n",
      "  ]\n",
      "\n",
      "\n",
      "====164====\n",
      "    \"\"\"Build a depthwise conv graph given `parameters`.\"\"\"\n",
      "    input_shape, filter_shape = get_tensor_shapes(parameters)\n",
      "    input_tensor = tf.compat.v1.placeholder(\n",
      "        dtype=tf.float32, name=\"input\", shape=input_shape)\n",
      "\n",
      "\n",
      "\n",
      "====165====\n",
      "    \"\"\"\n",
      "\n",
      "    input_shape, filter_shape = get_tensor_shapes(parameters)\n",
      "    values = [\n",
      "        create_tensor_data(np.float32, input_shape, min_value=-1, max_value=1)\n",
      "\n",
      "\n",
      "====166====\n",
      "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "\n",
      "====167====\n",
      "        filter_tensor,\n",
      "        output_shape=output_shape,\n",
      "        padding=\"SAME\",\n",
      "        strides=(1, 2, 2, 1))\n",
      "\n",
      "\n",
      "\n",
      "====168====\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Test configs for add_n.\"\"\"\n",
      "\n",
      "\n",
      "====169====\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import tensorflow.compat.v1 as tf\n",
      "\n",
      "\n",
      "====170====\n",
      "\n",
      "import tensorflow.compat.v1 as tf\n",
      "from tensorflow.lite.testing.zip_test_utils import create_tensor_data\n",
      "from tensorflow.lite.testing.zip_test_utils import make_zip_of_tests\n",
      "from tensorflow.lite.testing.zip_test_utils import register_make_test_function\n",
      "\n",
      "\n",
      "====171====\n",
      "    \"\"\"Actual function that generates examples.\"\"\"\n",
      "    test_parameters = [\n",
      "        {\n",
      "            \"input_dtype\": [tf.float32],\n",
      "            \"input_shape\": [[], [1], [1, 2], [5, 6, 7, 8], [3, 4, 5, 6]],\n",
      "\n",
      "\n",
      "====172====\n",
      "            \"fully_quantize\": [False],\n",
      "            \"input_range\": [[min_value, max_value]],\n",
      "        },\n",
      "        {\n",
      "            \"input_dtype\": [tf.float32],\n",
      "\n",
      "\n",
      "====173====\n",
      "\n",
      "@register_make_test_function()\n",
      "def make_topk_tests(options):\n",
      "  \"\"\"Make a set of tests to do topk.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "====174====\n",
      "  \"\"\"Create TOCO options to process a model.\n",
      "\n",
      "  Args:\n",
      "    data_types: input and inference types used by TOCO.\n",
      "    input_arrays: names of the input tensors\n",
      "\n",
      "\n",
      "====175====\n",
      "    inference_type = \"QUANTIZED_UINT8\"\n",
      "  s = (\" --input_data_types=%s\" % \",\".join(data_types) +\n",
      "       \" --inference_type=%s\" % inference_type +\n",
      "       \" --input_format=TENSORFLOW_GRAPHDEF\" + \" --output_format=TFLITE\" +\n",
      "       \" --input_arrays=%s\" % \",\".join(input_arrays) +\n",
      "\n",
      "\n",
      "====176====\n",
      "    converter: TFLiteConverter object.\n",
      "    **kwargs: Additional arguments to be passed into the converter. Supported\n",
      "      flags are {\"target_ops\", \"post_training_quantize\", \"quantize_to_float16\",\n",
      "      \"post_training_quantize_int8\", \"post_training_quantize_16x8\",\n",
      "      \"model_input_size\"}.\n",
      "\n",
      "\n",
      "====177====\n",
      "\n",
      "  Returns:\n",
      "    The converted TFLite model in serialized format.\n",
      "\n",
      "  Raises:\n",
      "\n",
      "\n",
      "====178====\n",
      "  for tensor in all_tensor_details:\n",
      "    if \"_int16\" in tensor[\"name\"]:\n",
      "      found_input = True\n",
      "      if tensor[\"dtype\"] is not np.int16:\n",
      "        raise ValueError(\"Activations should be int16.\")\n",
      "\n",
      "\n",
      "====179====\n",
      "  graph_def = _graph_pb2.GraphDef()\n",
      "  try:\n",
      "    graph_def.ParseFromString(file_content)\n",
      "  except (_text_format.ParseError, DecodeError):\n",
      "    if not isinstance(file_content, str):\n",
      "\n",
      "\n",
      "====180====\n",
      "    inputs, outputs = _convert_saved_model.get_inputs_outputs(signature_def)\n",
      "\n",
      "    return lambda input_data: sess.run(outputs, dict(zip(inputs, input_data)))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====181====\n",
      "def _compare_tf_tflite_results(tf_results,\n",
      "                               tflite_results,\n",
      "                               tflite_labels,\n",
      "                               tolerance=5):\n",
      "  \"\"\"Compare the result of TF and TFLite model.\n",
      "\n",
      "\n",
      "====182====\n",
      "def compare_tflite_keras_models_v2(tflite_model,\n",
      "                                   keras_model,\n",
      "                                   input_data=None,\n",
      "                                   input_data_range=None,\n",
      "                                   tolerance=5,\n",
      "\n",
      "\n",
      "====183====\n",
      "\n",
      "def compare_model_golden(tflite_model,\n",
      "                         input_data,\n",
      "                         golden_name,\n",
      "                         update_golden=False,\n",
      "\n",
      "\n",
      "====184====\n",
      "    if not quantized_tensors:\n",
      "      raise ValueError(\"--post_training_quantize flag was unable to quantize \"\n",
      "                       \"the graph as expected in TFLite.\")\n",
      "  elif not has_quant_tensor:\n",
      "    raise ValueError(\"--post_training_quantize flag was unable to quantize the \"\n",
      "\n",
      "\n",
      "====185====\n",
      "\n",
      "  Args:\n",
      "    directory: SavedModel directory to convert.\n",
      "    tag_set: Set of tags identifying the MetaGraphDef within the SavedModel to\n",
      "      analyze. All tags in the tag set must be present.\n",
      "\n",
      "\n",
      "====186====\n",
      "  tflite_model_float = _convert(converter, version=2, **kwargs)\n",
      "\n",
      "  interpreter_float = _get_tflite_interpreter(tflite_model_float)\n",
      "  interpreter_float.allocate_tensors()\n",
      "  float_tensors = interpreter_float.get_tensor_details()\n",
      "\n",
      "\n",
      "====187====\n",
      "      quantize_to_float16=True,\n",
      "      **kwargs)\n",
      "\n",
      "  interpreter_quant = _get_tflite_interpreter(tflite_model_quant)\n",
      "  interpreter_quant.allocate_tensors()\n",
      "\n",
      "\n",
      "====188====\n",
      "    input_data: np.ndarray to pass into models during inference.\n",
      "    golden_name: Optional golden values to compare the output of the model\n",
      "      against.\n",
      "    update_golden: Whether to update the golden values with the model output\n",
      "      instead of comparing against them.\n",
      "\n",
      "\n",
      "====189====\n",
      "class EvaluateSavedModel(test.TestCase):\n",
      "\n",
      "  def testFloat(self):\n",
      "    saved_model_dir = os.path.join(self.get_temp_dir(), 'simple_savedmodel')\n",
      "    with ops.Graph().as_default():\n",
      "\n",
      "\n",
      "====190====\n",
      "\n",
      "    input_size = [5, 5, 3]\n",
      "    kernel_size = [3, 3, 1]\n",
      "    layer_name = 'test_conv2d'\n",
      "    input_0 = keras.layers.Input(shape=input_size)\n",
      "\n",
      "\n",
      "====191====\n",
      "    keras.backend.clear_session()\n",
      "\n",
      "    xs = np.array([-1, 0, 1, 2, 3, 4])\n",
      "    ys = np.array([-3, -1, 1, 3, 5, 7])\n",
      "\n",
      "\n",
      "\n",
      "====192====\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "\n",
      "\n",
      "====193====\n",
      "  elif op_name in conversion_log.custom_ops:\n",
      "    return \"CUSTOM OP\"\n",
      "  else:\n",
      "    return \"SELECT OP\"\n",
      "\n",
      "\n",
      "\n",
      "====194====\n",
      "        should point to a '.html' file with date and time in its name.\n",
      "        e.g. 2019-01-01-10:05.toco_report.html.\n",
      "\n",
      "    Raises:\n",
      "      IOError: File doesn't exist.\n",
      "\n",
      "\n",
      "====195====\n",
      "  with io.open(dot_before_path, \"r\", encoding=\"utf-8\") as f:\n",
      "    dot_before = f.read().rstrip()\n",
      "  with io.open(dot_after_path, \"r\", encoding=\"utf-8\") as f:\n",
      "    dot_after = f.read().rstrip()\n",
      "\n",
      "\n",
      "\n",
      "====196====\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "\n",
      "\n",
      "====197====\n",
      "    toco_conversion_log_after = _toco_conversion_log_pb2.TocoConversionLog()\n",
      "\n",
      "    toco_conversion_log_before.op_list.extend([\n",
      "        \"Conv1\", \"Conv2\", \"Identity\", \"Reshape\", \"Dense\", \"Dense\", \"CustomOp\",\n",
      "        \"AvgPool3D\", \"Softmax\"\n",
      "\n",
      "\n",
      "====198====\n",
      "    html_generator.generate(toco_conversion_log_before,\n",
      "                            toco_conversion_log_after, True,\n",
      "                            \"digraph  {a -> b}\", \"digraph  {a -> b}\", \"\",\n",
      "                            \"/path/to/flatbuffer\")\n",
      "\n",
      "\n",
      "\n",
      "====199====\n",
      "      self.num = len(lines)\n",
      "\n",
      "  def test_read_data(self):\n",
      "    self.assertEqual(len(self.data), self.num)\n",
      "    self.assertIsInstance(self.data, list)\n",
      "\n",
      "\n",
      "====200====\n",
      "    self.assertIsInstance(self.data[0], dict)\n",
      "    self.assertEqual(\n",
      "        set(list(self.data[-1])), set([\"gesture\", \"accel_ms2_xyz\", \"name\"]))\n",
      "\n",
      "  def test_split_data(self):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Json snippets\n",
    "#\n",
    "# \"snippets\": [\n",
    "#     \"id\"\n",
    "#     \"snippet\"\n",
    "#     \"language\"\n",
    "#     \"repo_file_name\"\n",
    "# ]\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('..\\\\data\\\\python-202504161219.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "ctr = 1\n",
    "for i in data[\"snippets\"]:\n",
    "    print(f\"\\n===={ctr}====\\n{i[\"snippet\"]}\")\n",
    "    ctr = ctr + 1\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c6c04-dfe9-4c35-8a1b-20016da6d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random snippets\n",
    "\n",
    "import json\n",
    "# Json snippets\n",
    "#\n",
    "# \"snippets\": [\n",
    "#     \"id\"\n",
    "#     \"snippet\"\n",
    "#     \"language\"\n",
    "#     \"repo_file_name\"\n",
    "# ]\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('..\\\\data\\\\python-202504161219.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "ctr = 1\n",
    "for i in data[\"snippets\"]:\n",
    "    print(f\"\\n===={ctr}====\\n{i[\"snippet\"]}\")\n",
    "    ctr = ctr + 1\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b205e-f381-47f4-b14c-fb462b25addd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
